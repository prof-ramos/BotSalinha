# BotSalinha M√©tricas

Este diret√≥rio cont√©m scripts para gera√ß√£o e an√°lise de m√©tricas de performance e qualidade do BotSalinha.

## üöÄ Uso R√°pido

### Executar um script individual

```bash
# Usar configura√ß√µes padr√£o
uv run python metricas/gerar_performance.py

# Com argumentos personalizados
uv run python metricas/gerar_performance.py --prompts 10 --output meus_resultados.csv --quiet
```

### Executar todas as m√©tricas (relat√≥rio consolidado)

```bash
# Executar todos os testes
uv run python metricas/run_all_metrics.py

# Pular testes espec√≠ficos
uv run python metricas/run_all_metrics.py --skip-performance --skip-quality
```

---

## üìä Scripts Dispon√≠veis

### 1. M√©tricas de Qualidade RAG

**Script:** `gerar_qualidade.py`

Executa consultas de teste no sistema RAG simulando requisi√ß√µes reais de usu√°rios.

**M√©tricas geradas:**
- Similaridade m√©dia e m√°xima por query
- Distribui√ß√£o de confian√ßa (ALTA, M√âDIA, BAIXA, SEM_RAG)
- Chunks recuperados por query
- Lat√™ncia de busca

**Argumentos CLI:**
```bash
uv run python metricas/gerar_qualidade.py [OPTIONS]

Options:
  --output, -o PATH      Caminho do CSV de sa√≠da (default: metricas/qualidade_rag.csv)
  --queries, -q INT      N√∫mero de queries a testar (default: 6)
  --verbose, -v          Modo verbose de logging
  --quiet, -q            Suprimir logs informativos
  --help                 Mostrar mensagem de ajuda
```

**Arquivos gerados:**
- `qualidade_rag.csv` - Dados brutos
- `qualidade_rag_summary.csv` - M√©tricas agregadas

---

### 2. M√©tricas de Performance End-to-End

**Script:** `gerar_performance.py`

Testa a lat√™ncia real de ponta a ponta do AgentWrapper para responder prompts no chat.

**M√©tricas geradas:**
- Tempo de resposta por prompt
- Comprimento da resposta gerada
- Uso de RAG (sim/n√£o)
- Taxa de sucesso
- Percentil 95 de lat√™ncia

**Argumentos CLI:**
```bash
uv run python metricas/gerar_performance.py [OPTIONS]

Options:
  --output, -o PATH      Caminho do CSV de sa√≠da (default: metricas/performance_geral.csv)
  --prompts, -p INT      N√∫mero de prompts a testar (default: 4)
  --verbose, -v          Modo verbose de logging
  --quiet, -q            Suprimir logs informativos
  --help                 Mostrar mensagem de ajuda
```

**Arquivos gerados:**
- `performance_geral.csv` - Dados brutos
- `performance_geral_summary.csv` - M√©tricas agregadas

---

### 3. M√©tricas de Performance de RAG (Componentes)

**Script:** `gerar_performance_rag.py`

Isola os componentes do RAG para medi√ß√£o individual.

**M√©tricas geradas:**
- Tempo de gera√ß√£o de embedding (OpenAI API)
- Tempo de busca vetorial (SQLite)
- Correla√ß√£o tamanho do texto ‚Üí tempo de embedding
- Chunks encontrados por busca

**Argumentos CLI:**
```bash
uv run python metricas/gerar_performance_rag.py [OPTIONS]

Options:
  --output, -o PATH      Caminho do CSV de sa√≠da (default: metricas/performance_rag_componentes.csv)
  --texts, -t INT        N√∫mero de textos a testar (default: 6)
  --verbose, -v          Modo verbose de logging
  --quiet, -q            Suprimir logs informativos
  --help                 Mostrar mensagem de ajuda
```

**Arquivos gerados:**
- `performance_rag_componentes.csv` - Dados brutos
- `performance_rag_componentes_summary.csv` - M√©tricas agregadas

---

### 4. M√©tricas de Performance de Acesso ao Banco

**Script:** `gerar_performance_acesso.py`

Executa opera√ß√µes massivas de escrita e leitura no SQLite para testar escalabilidade CRUD.

**M√©tricas geradas:**
- Throughput (opera√ß√µes/segundo)
- Lat√™ncia m√©dia de insert
- Lat√™ncia m√©dia de read
- Ratio insert vs read

**Argumentos CLI:**
```bash
uv run python metricas/gerar_performance_acesso.py [OPTIONS]

Options:
  --output, -o PATH      Caminho do CSV de sa√≠da (default: metricas/performance_acesso.csv)
  --inserts, -i INT      N√∫mero de opera√ß√µes de insert (default: 50)
  --reads, -r INT        N√∫mero de opera√ß√µes de read (default: 100)
  --verbose, -v          Modo verbose de logging
  --quiet, -q            Suprimir logs informativos
  --help                 Mostrar mensagem de ajuda
```

**Arquivos gerados:**
- `performance_acesso.csv` - Dados brutos
- `performance_acesso_summary.csv` - M√©tricas agregadas

---

### 5. Script Consolidado (Todas as M√©tricas)

**Script:** `run_all_metrics.py`

Executa todos os scripts de m√©tricas em sequ√™ncia e gera um relat√≥rio HTML consolidado.

**Funcionalidades:**
- Execu√ß√£o sequencial dos 4 scripts
- Relat√≥rio HTML com:
  - Cards de sum√°rio (total/sucesso/falha)
  - Gr√°ficos de barras CSS
  - Tabelas com dados
  - Status badges

**Argumentos CLI:**
```bash
uv run python metricas/run_all_metrics.py [OPTIONS]

Options:
  --skip-performance     Pular teste de performance end-to-end
  --skip-quality         Pular teste de qualidade RAG
  --skip-access          Pular teste de acesso ao banco
  --skip-rag             Pular teste de componentes RAG
  --help                 Mostrar mensagem de ajuda
```

**Arquivo gerado:**
- `relatorio_consolidado_<timestamp>.html` - Relat√≥rio visual completo

---

## üìà Formato dos Arquivos de Sa√≠da

### CSV Principal (dados brutos)
Cont√©m uma linha por medi√ß√£o com todos os campos coletados.

### CSV Summary (`_summary.csv`)
Cont√©m m√©tricas agregadas calculadas:
- M√©dias, medianas, percentis
- Distribui√ß√µes (porcentagens)
- Correla√ß√µes
- Throughput

### Console Output
Cada script exibe um sum√°rio estat√≠stico formatado no console ao final da execu√ß√£o:

```
============================================================
SUM√ÅRIO ESTAT√çSTICO - PERFORMANCE ACESSO DB
============================================================
Throughput:                    792.18 ops/segundo

Compara√ß√£o Insert vs Read:
  Insert: 2.74ms avg (10 ops)
  Read:   0.52ms avg (20 ops)
  Ratio (Read/Insert):         0.19x

Total de opera√ß√µes:            30
Tempo total:                   0.038s
============================================================
```

---

## üéØ Exemplos de Uso

### Teste r√°pido (defaults)
```bash
uv run python metricas/run_all_metrics.py --skip-performance
```

### Teste completo com customiza√ß√£o
```bash
# Acesso ao banco - mais opera√ß√µes
uv run python metricas/gerar_performance_acesso.py --inserts 100 --reads 500

# RAG qualidade - mais queries
uv run python metricas/gerar_qualidade.py --queries 20 --output qualidade_extenso.csv
```

### Modo silencioso (para CI/CD)
```bash
uv run python metricas/run_all_metrics.py --quiet
```

### Ver detalhes com verbose
```bash
uv run python metricas/gerar_performance.py --verbose --prompts 2
```

---

## üìã Notas T√©cnicas

- Todos os scripts usam `asyncio` para opera√ß√µes ass√≠ncronas
- O banco de dados usa modo WAL para melhor concorr√™ncia
- Embeddings s√£o gerados via OpenAI API (text-embedding-3-small)
- Testes limpeza ap√≥s execu√ß√£o (delete de dados de teste)
- Formato de data/hora nos relat√≥rios: `YYYYMMDD_HHMMSS`
