<!-- Parent: ../AGENTS.md -->
<!-- Generated: 2026-02-28 | Updated: 2026-02-28 -->

# metricas

## Purpose
Metrics and performance evaluation directory for BotSalinha RAG system. Contains scripts, data, and reports for measuring the performance of the Retrieval-Augmented Generation system, including quality metrics, access metrics, and overall performance tracking.

## Key Files
| File | Description |
|------|-------------|
| `gerar_performance.py` | Script for generating performance metrics |
| `gerar_performance_acesso.py` | Performance metrics for access patterns |
| `gerar_performance_rag.py` | RAG-specific performance metrics |
| `gerar_qualidade.py` | Quality evaluation metrics |

## Subdirectories
| Directory | Purpose |
|-----------|---------|
| `utils.py` | Utility functions for metrics calculation |

## For AI Agents

### Working In This Directory
- Generate performance reports and quality metrics
- Analyze RAG system effectiveness
- Track bot response accuracy and performance

### Testing Requirements
- Validate metric generation algorithms
- Test performance under various loads
- Verify metric accuracy and consistency

### Common Patterns
- CSV-based data storage for metrics
- Statistical analysis for performance evaluation
- Automated reporting and visualization

## Dependencies

### Internal
- RAG system components for performance evaluation
- Database access for metrics collection
- Configuration settings for thresholds

### External
- Pandas for data analysis
- Matplotlib/Seaborn for visualization
- Statistical analysis libraries
- CSV handling utilities

<!-- MANUAL: Any manually added notes below this line are preserved on regeneration -->
