# Schema RAG â€” BotSalinha

ReferÃªncia tÃ©cnica completa do sistema de Retrieval-Augmented Generation (RAG).

---

## SumÃ¡rio

1. [VisÃ£o Geral](#1-visÃ£o-geral)
2. [Schema do Banco de Dados](#2-schema-do-banco-de-dados)
3. [Modelos Pydantic](#3-modelos-pydantic)
4. [ServiÃ§os](#4-serviÃ§os)
5. [Pipeline de IngestÃ£o](#5-pipeline-de-ingestÃ£o)
6. [Pipeline de Consulta](#6-pipeline-de-consulta)
7. [Embeddings](#7-embeddings)
8. [ConfiguraÃ§Ã£o](#8-configuraÃ§Ã£o)
9. [Thresholds e Limites](#9-thresholds-e-limites)
10. [Erros e ExceÃ§Ãµes](#10-erros-e-exceÃ§Ãµes)

---

## 1. VisÃ£o Geral

O RAG do BotSalinha indexa documentos jurÃ­dicos (`.docx`) em fragmentos de texto
(_chunks_) com embeddings vetoriais, e usa busca semÃ¢ntica por similaridade cosseno
para enriquecer as respostas do agente com referÃªncias reais Ã s leis e jurisprudÃªncia.

```
Arquivo .docx
    â†“  DOCXParser
ParÃ¡grafos estruturados
    â†“  ChunkExtractor
Chunks com metadata (art., inciso, Â§, marcadoresâ€¦)
    â†“  EmbeddingService (OpenAI text-embedding-3-small)
Vetores 1536-dim
    â†“  SQLite (LargeBinary)
VectorStore
    â†‘  QueryService (busca cosseno)
Pergunta do usuÃ¡rio â†’ RAGContext â†’ Prompt aumentado â†’ Resposta com fontes
```

---

## 2. Schema do Banco de Dados

### 2.1 Tabela `rag_documents`

```sql
CREATE TABLE rag_documents (
    id           INTEGER  PRIMARY KEY AUTOINCREMENT,
    nome         VARCHAR(255) NOT NULL,
    arquivo_origem VARCHAR(500) NOT NULL,
    chunk_count  INTEGER  NOT NULL DEFAULT 0,
    token_count  INTEGER  NOT NULL DEFAULT 0,
    file_hash    VARCHAR(64)  DEFAULT NULL,       -- SHA-256 hex (64 chars)
    created_at   DATETIME NOT NULL
);

CREATE INDEX ix_rag_documents_nome      ON rag_documents (nome);
CREATE INDEX ix_rag_documents_file_hash ON rag_documents (file_hash);

-- UNIQUE permite mÃºltiplos NULL (linhas legadas sem hash)
CREATE UNIQUE INDEX uq_rag_documents_file_hash ON rag_documents (file_hash)
    WHERE file_hash IS NOT NULL;
```

#### Colunas

| Coluna           | Tipo         | NulÃ¡vel | PadrÃ£o | DescriÃ§Ã£o                                         |
| ---------------- | ------------ | ------- | ------ | ------------------------------------------------- |
| `id`             | INTEGER      | NÃƒO     | auto   | Chave primÃ¡ria                                    |
| `nome`           | VARCHAR(255) | NÃƒO     | â€”      | Nome legÃ­vel do documento (ex.: `"CF/88"`)        |
| `arquivo_origem` | VARCHAR(500) | NÃƒO     | â€”      | Caminho do arquivo de origem                      |
| `chunk_count`    | INTEGER      | NÃƒO     | 0      | NÃºmero de chunks indexados                        |
| `token_count`    | INTEGER      | NÃƒO     | 0      | Total de tokens estimados                         |
| `file_hash`      | VARCHAR(64)  | SIM     | NULL   | SHA-256 hex do arquivo (deduplicaÃ§Ã£o)             |
| `created_at`     | DATETIME     | NÃƒO     | â€”      | Timestamp UTC da criaÃ§Ã£o                          |

---

### 2.2 Tabela `rag_chunks`

```sql
CREATE TABLE rag_chunks (
    id           VARCHAR(255) PRIMARY KEY,     -- ex.: "CF_88-0001"
    documento_id INTEGER  NOT NULL REFERENCES rag_documents(id) ON DELETE CASCADE,
    texto        TEXT     NOT NULL,
    metadados    TEXT     NOT NULL,            -- JSON serializado de ChunkMetadata
    token_count  INTEGER  NOT NULL,
    embedding    BLOB     DEFAULT NULL,        -- float32[1536] serializado
    created_at   DATETIME NOT NULL
);

CREATE INDEX ix_rag_chunks_documento_id ON rag_chunks (documento_id);
```

#### Colunas

| Coluna         | Tipo        | NulÃ¡vel | PadrÃ£o | DescriÃ§Ã£o                                          |
| -------------- | ----------- | ------- | ------ | -------------------------------------------------- |
| `id`           | VARCHAR(255)| NÃƒO     | â€”      | PK no formato `"<nome_doc>-<seq:04d>"`             |
| `documento_id` | INTEGER     | NÃƒO     | â€”      | FK â†’ `rag_documents.id` (CASCADE DELETE)           |
| `texto`        | TEXT        | NÃƒO     | â€”      | ConteÃºdo textual do chunk                          |
| `metadados`    | TEXT        | NÃƒO     | â€”      | JSON de `ChunkMetadata` (artigo, marcadores, etc.) |
| `token_count`  | INTEGER     | NÃƒO     | â€”      | Tokens estimados (`len(texto) / 4`)                |
| `embedding`    | BLOB        | SIM     | NULL   | 1536 Ã— float32 = 6.144 bytes                       |
| `created_at`   | DATETIME    | NÃƒO     | â€”      | Timestamp UTC da criaÃ§Ã£o                           |

---

### 2.3 Diagrama Entidade-Relacionamento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            rag_documents             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PK  id           INTEGER            â”‚
â”‚     nome         VARCHAR(255)       â”‚
â”‚     arquivo_origem VARCHAR(500)     â”‚
â”‚     chunk_count  INTEGER            â”‚
â”‚     token_count  INTEGER            â”‚
â”‚     file_hash    VARCHAR(64) UNIQUE â”‚  â† SHA-256, NULL = legado
â”‚     created_at   DATETIME           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ 1
                    â”‚
                    â”‚ N
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              rag_chunks              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PK  id           VARCHAR(255)       â”‚  â† "CF_88-0001"
â”‚ FK  documento_id INTEGER            â”‚  â†’ rag_documents.id
â”‚     texto        TEXT               â”‚
â”‚     metadados    TEXT (JSON)        â”‚  â† ChunkMetadata serializado
â”‚     token_count  INTEGER            â”‚
â”‚     embedding    BLOB               â”‚  â† float32[1536]
â”‚     created_at   DATETIME           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.4 MigraÃ§Ãµes Alembic

| RevisÃ£o                                            | DescriÃ§Ã£o                                          |
| -------------------------------------------------- | -------------------------------------------------- |
| `20260228_0236_â€¦_add_rag_documents_and_chunks`     | Cria as tabelas `rag_documents` e `rag_chunks`     |
| `20260228_1000_add_embedding_column_to_rag_chunks` | Adiciona coluna `embedding BLOB` em `rag_chunks`   |
| `20260228_1100_add_file_hash_to_rag_documents`     | Adiciona `file_hash VARCHAR(64)` com UNIQUE e Ã­ndice |

---

## 3. Modelos Pydantic

Todos em `src/rag/models.py`.

### 3.1 `ChunkMetadata`

Metadados estruturais e semÃ¢nticos de um chunk de texto jurÃ­dico.

```python
class ChunkMetadata(BaseModel):
    # LocalizaÃ§Ã£o no documento
    documento:    str           # ex.: "CF/88"      â€” obrigatÃ³rio
    titulo:       str | None    # TÃ­tulo de seÃ§Ã£o
    capitulo:     str | None    # CapÃ­tulo
    secao:        str | None    # SeÃ§Ã£o
    artigo:       str | None    # ex.: "5"
    paragrafo:    str | None    # ex.: "Ãºnico" ou "1"
    inciso:       str | None    # ex.: "I", "II", "III"
    tipo:         str | None    # "caput" | "inciso" | "heading" | "content"

    # Marcadores de atenÃ§Ã£o (extraÃ­dos por regex)
    marca_atencao:    bool = False   # Texto marcado com #AtenÃ§Ã£o:
    marca_stf:        bool = False   # MenÃ§Ã£o ao STF / Supremo Tribunal Federal
    marca_stj:        bool = False   # MenÃ§Ã£o ao STJ / Superior Tribunal de JustiÃ§a
    marca_concurso:   bool = False   # Relevante para concursos pÃºblicos
    marca_crime:      bool = False   # Direito penal â€” tipificaÃ§Ã£o
    marca_pena:       bool = False   # Pena / sanÃ§Ã£o aplicÃ¡vel
    marca_hediondo:   bool = False   # Crimes hediondos (Lei 8.072)
    marca_acao_penal: bool = False   # AÃ§Ã£o penal pÃºblica ou privada
    marca_militar:    bool = False   # CÃ³digo Penal Militar / legislaÃ§Ã£o militar

    # InformaÃ§Ãµes de prova/questÃ£o
    banca: str | None    # ex.: "CEBRASPE", "FCC", "VUNESP", "FGV"
    ano:   str | None    # ex.: "2024"
```

### 3.2 `Chunk`

```python
class Chunk(BaseModel):
    chunk_id:          str           # ex.: "CF_88-0001"
    documento_id:      int           # FK â†’ DocumentORM.id
    texto:             str           # ConteÃºdo textual
    metadados:         ChunkMetadata
    token_count:       int           # â‰¥ 0
    posicao_documento: float         # 0.0 (inÃ­cio) a 1.0 (fim)
```

### 3.3 `Document`

```python
class Document(BaseModel):
    id:             int
    nome:           str
    arquivo_origem: str
    chunk_count:    int       # â‰¥ 0
    token_count:    int       # â‰¥ 0
    file_hash:      str | None  # SHA-256 hex ou None (legado)
```

### 3.4 `ConfiancaLevel`

```python
class ConfiancaLevel(StrEnum):
    ALTA   = "alta"     # avg_similarity â‰¥ 0.85
    MEDIA  = "media"    # avg_similarity â‰¥ 0.70
    BAIXA  = "baixa"    # avg_similarity â‰¥ 0.60
    SEM_RAG = "sem_rag" # Nenhum resultado ou abaixo de 0.60
```

### 3.5 `RAGContext`

Resultado da busca semÃ¢ntica â€” injetado no prompt do agente.

```python
class RAGContext(BaseModel):
    chunks_usados:  list[Chunk]   # Chunks recuperados
    similaridades:  list[float]   # Score por chunk (mesma ordem)
    confianca:      ConfiancaLevel
    fontes:         list[str]     # CitaÃ§Ãµes formatadas

    # Invariante: len(chunks_usados) == len(similaridades)
```

**Exemplo de `fontes`:**

```python
[
    "CF/88, Art. 5, Â§ 1, Inciso I, TÃ­tulo: Dos Direitos e Garantias Fundamentais",
    "CF/88, Art. 6, CapÃ­tulo: Dos Direitos Sociais",
]
```

---

## 4. ServiÃ§os

### 4.1 `EmbeddingService` â€” `src/rag/services/embedding_service.py`

Gera vetores via OpenAI `text-embedding-3-small` (1536 dimensÃµes).

```
embed_text(text: str) â†’ list[float]           # 1 requisiÃ§Ã£o
embed_batch(texts: list[str]) â†’ list[list[float]]   # Batching automÃ¡tico
```

- Texto vazio â†’ vetor zero `[0.0] * 1536`
- Lotes > 200.000 tokens sÃ£o divididos automaticamente
- Estimativa de tokens: `len(text) / 4`
- Retry automÃ¡tico (3 tentativas com backoff)

### 4.2 `IngestionService` â€” `src/rag/services/ingestion_service.py`

Orquestra o pipeline completo de ingestÃ£o.

```
ingest_document(file_path, document_name) â†’ Document
reindex(documents_dir, pattern="*.docx")  â†’ dict[str, int | float]
```

**`reindex` retorna:**

```python
{
    "chunks_count":      int,
    "documents_count":   int,
    "duration_seconds":  float,
    "success":           bool,
}
```

### 4.3 `QueryService` â€” `src/rag/services/query_service.py`

Busca semÃ¢ntica e construÃ§Ã£o do contexto para o agente.

```
query(query_text, top_k?, min_similarity?, documento_id?, filters?) â†’ RAGContext
query_by_tipo(query_text, tipo, top_k?)                             â†’ RAGContext
should_augment_prompt(context: RAGContext)                          â†’ bool
get_augmentation_text(context: RAGContext)                          â†’ str
```

**Valores de `tipo` em `query_by_tipo`:**

| Valor           | Filtro aplicado                      |
| --------------- | ------------------------------------ |
| `"artigo"`      | `tipo = "caput"` ou `"inciso"`       |
| `"jurisprudencia"` | `marca_stf = true` ou `marca_stj = true` |
| `"questao"`     | `marca_concurso = true`              |
| `"nota"`        | `tipo = "content"` sem marcadores    |
| `"todos"`       | Sem filtro                           |

### 4.4 `VectorStore` â€” `src/rag/storage/vector_store.py`

Armazena e recupera embeddings diretamente no SQLite.

```
search(query_embedding, limit?, min_similarity?, documento_id?, filters?) â†’ list[(Chunk, float)]
add_embeddings(chunks_with_embeddings)                                     â†’ None
get_chunk_by_id(chunk_id)                                                  â†’ Chunk | None
count_chunks(documento_id?)                                                â†’ int
```

**Algoritmo de busca:**

1. Carrega todos os `ChunkORM` com `embedding IS NOT NULL`
2. Aplica filtros de `documento_id` e `metadados` (via `JSON_EXTRACT`)
3. Calcula similaridade cosseno em Python para cada candidato
4. Filtra por `min_similarity`
5. Ordena por score desc, aplica `limit`

### 4.5 `ConfiancaCalculator` â€” `src/rag/utils/confianca_calculator.py`

```
calculate(chunks_with_scores)              â†’ ConfiancaLevel
calculate_from_context(context)            â†’ ConfiancaLevel
get_confidence_message(level)              â†’ str   # com emoji
should_use_rag(level)                      â†’ bool
format_sources(chunks_with_scores)         â†’ list[str]
```

**Mensagens por nÃ­vel:**

| NÃ­vel     | Mensagem                                                                 |
| --------- | ------------------------------------------------------------------------ |
| `ALTA`    | `âœ… [ALTA CONFIANÃ‡A] Resposta baseada em documentos jurÃ­dicos verificados` |
| `MEDIA`   | `âš ï¸ [MÃ‰DIA CONFIANÃ‡A] Resposta parcialmente baseada em documentos`        |
| `BAIXA`   | `âŒ [BAIXA CONFIANÃ‡A] InformaÃ§Ãµes limitadas encontradas`                  |
| `SEM_RAG` | `â„¹ï¸ [SEM RAG] NÃ£o encontrei informaÃ§Ãµes especÃ­ficas nos documentos`       |

---

## 5. Pipeline de IngestÃ£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PIPELINE DE INGESTÃƒO                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[0] DEDUPLICAÃ‡ÃƒO
    â€¢ Calcular SHA-256 do arquivo (blocos de 64 KiB)
    â€¢ SELECT DocumentORM WHERE file_hash = <hash>
    â€¢ Se encontrado â†’ DuplicateDocumentError(existing_id, existing_nome, file_hash)

[1] PARSE
    â€¢ DOCXParser.parse() â†’ list[dict]
    â€¢ Extrai: text, style, is_heading (nÃ­vel 1-9), is_bold, is_italic
    â€¢ Normaliza encoding UTF-8 / mojibake latin-1

[2] CRIAR DOCUMENTO
    â€¢ INSERT DocumentORM (nome, arquivo_origem, file_hash, created_at)
    â€¢ FLUSH para obter ID autogerado

[3] CHUNKING
    â€¢ ChunkExtractor.extract_chunks()
    â€¢ Algoritmo greedy bin-packing:
      - Acumula parÃ¡grafos atÃ© max_tokens (500)
      - Quebra em headings nÃ­vel 1-2 ou ao atingir limite
      - Adiciona overlap de 50 tokens do chunk anterior
    â€¢ Preserva contexto hierÃ¡rquico: titulo â†’ capitulo â†’ secao
    â€¢ MetadataExtractor.extract() por chunk (regex para art., Â§, incisos, marcadores)
    â€¢ chunk_id = "{nome_sanitizado}-{seq:04d}"
    â€¢ posicao_documento = (posiÃ§Ã£o do chunk) / (total de parÃ¡grafos)

[4] EMBEDDINGS
    â€¢ EmbeddingService.embed_batch([chunk.texto for chunk in chunks])
    â€¢ Um Ãºnico batch por documento (dividido se > 200.000 tokens)
    â€¢ Retorna list[list[float]] â€” 1536 floats por chunk

[5] CRIAR CHUNKS
    â€¢ Para cada (chunk, embedding):
      - serialize_embedding(embedding) â†’ bytes (float32, 6.144 bytes)
      - INSERT ChunkORM (id, documento_id, texto, metadados JSON, token_count, embedding)

[6] ATUALIZAR ESTATÃSTICAS
    â€¢ UPDATE DocumentORM SET chunk_count = N, token_count = sum(tokens)

[7] COMMIT
    â€¢ session.commit()

[8] RETORNAR
    â€¢ Document Pydantic com file_hash preenchido
```

---

## 6. Pipeline de Consulta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PIPELINE DE CONSULTA                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[1] EMBEDDING DA QUERY
    â€¢ EmbeddingService.embed_text(query_text)
    â€¢ â†’ list[float] de 1536 dimensÃµes

[2] BUSCA VETORIAL
    â€¢ VectorStore.search(query_embedding, limit=top_k, min_similarity=0.6)
    â€¢ Carrega ChunkORMs com embedding IS NOT NULL
    â€¢ Aplica filtros opcionais (documento_id, tipo, marcadores)
    â€¢ cosine_similarity(query_vec, chunk_vec) para cada candidato
    â€¢ Filtra scores < min_similarity
    â€¢ Ordena desc, retorna top_k

[3] CÃLCULO DE CONFIANÃ‡A
    â€¢ avg_similarity = mean([score for _, score in resultados])
    â€¢ ALTA   : avg â‰¥ 0.85
    â€¢ MEDIA  : avg â‰¥ 0.70
    â€¢ BAIXA  : avg â‰¥ 0.60
    â€¢ SEM_RAG: avg < 0.60 ou nenhum resultado

[4] FORMATAR FONTES
    â€¢ ConfiancaCalculator.format_sources(chunks_with_scores)
    â€¢ Gera strings: "CF/88, Art. 5, Â§ 1, Inciso II, TÃ­tulo: Fundamentais"

[5] MONTAR RAGContext
    â€¢ chunks_usados, similaridades, confianca, fontes

[6] AUMENTAR PROMPT (se confianca â‰  SEM_RAG)
    â€¢ QueryService.get_augmentation_text(context)
    â€¢ Formato injetado:
        [ALTA CONFIANÃ‡A] Resposta baseada em documentos jurÃ­dicos verificados.

        === Contexto JurÃ­dico Relevante ===
        ğŸ“„ [Similaridade: 0.92] CF/88, Art. 5, caput
        "Todos sÃ£o iguais perante a lei, sem distinÃ§Ã£o de qualquer natureza..."

        âš–ï¸ [Similaridade: 0.87] CF/88, Art. 5, Inciso I
        "homens e mulheres sÃ£o iguais em direitos e obrigaÃ§Ãµes..."

        InstruÃ§Ãµes: Use apenas as informaÃ§Ãµes acima para fundamentar sua resposta.
        Cite as fontes fornecidas com precisÃ£o.
```

---

## 7. Embeddings

### 7.1 Modelo

| Atributo         | Valor                       |
| ---------------- | --------------------------- |
| Provedor         | OpenAI                      |
| Modelo           | `text-embedding-3-small`    |
| DimensÃµes        | 1536                        |
| Tipo             | `float32`                   |
| Tamanho em bytes | 1536 Ã— 4 = **6.144 bytes**  |
| Similaridade     | Cosseno                     |

### 7.2 SerializaÃ§Ã£o

```python
# float list â†’ bytes (armazenamento SQLite BLOB)
def serialize_embedding(embedding: list[float]) -> bytes:
    return np.array(embedding, dtype=np.float32).tobytes()

# bytes â†’ float list (recuperaÃ§Ã£o)
def deserialize_embedding(blob: bytes) -> list[float]:
    return np.frombuffer(blob, dtype=np.float32).tolist()
```

### 7.3 Similaridade Cosseno

```python
def cosine_similarity(a: list[float], b: list[float]) -> float:
    dot = sum(x * y for x, y in zip(a, b))
    norm_a = sum(x * x for x in a) ** 0.5
    norm_b = sum(x * x for x in b) ** 0.5
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return dot / (norm_a * norm_b)
    # Range: [-1.0, 1.0] â€” vetores idÃªnticos = 1.0
```

---

## 8. ConfiguraÃ§Ã£o

SeÃ§Ã£o `rag` em `src/config/settings.py` (lida via `YAML` + `Pydantic Settings`):

```python
class RAGConfig(BaseSettings):
    enabled:             bool  = True
    top_k:               int   = 5          # 1â€“20
    min_similarity:      float = 0.6        # 0.0â€“1.0
    max_context_tokens:  int   = 2000       # 100â€“8000
    documents_path:      str   = "data/documents"
    embedding_model:     str   = "text-embedding-3-small"
    confidence_threshold: float = 0.70      # threshold para nÃ­vel ALTA
```

VariÃ¡veis de ambiente correspondentes (prefixo `RAG__`):

```env
RAG__ENABLED=true
RAG__TOP_K=5
RAG__MIN_SIMILARITY=0.6
RAG__MAX_CONTEXT_TOKENS=2000
RAG__DOCUMENTS_PATH=data/documents
RAG__EMBEDDING_MODEL=text-embedding-3-small
RAG__CONFIDENCE_THRESHOLD=0.70
```

---

## 9. Thresholds e Limites

| ParÃ¢metro                       | Valor           | Fonte                            |
| ------------------------------- | --------------- | -------------------------------- |
| DimensÃ£o do embedding           | **1536**        | `EmbeddingService.EMBEDDING_DIM` |
| Max tokens por chunk            | **500**         | `ChunkExtractor` (configurÃ¡vel)  |
| Overlap entre chunks            | **50 tokens**   | `ChunkExtractor`                 |
| Tamanho mÃ­nimo do chunk         | **100 tokens**  | `ChunkExtractor`                 |
| Top K resultados (padrÃ£o)       | **5**           | `RAGConfig.top_k`                |
| Similaridade mÃ­nima (padrÃ£o)    | **0.60**        | `RAGConfig.min_similarity`       |
| Threshold ALTA confianÃ§a        | **â‰¥ 0.85**      | `ConfiancaCalculator`            |
| Threshold MÃ‰DIA confianÃ§a       | **â‰¥ 0.70**      | `ConfiancaCalculator`            |
| Threshold BAIXA confianÃ§a       | **â‰¥ 0.60**      | `ConfiancaCalculator`            |
| Max tokens por batch OpenAI     | **200.000**     | `EmbeddingService` (seguro)      |
| Limite real da API OpenAI       | 300.000         | ReferÃªncia interna               |
| Estimativa tokens (portuguÃªs)   | **4 chars/tok** | `EmbeddingService`, `ChunkExtractor` |
| Max contexto injetado no prompt | **2.000 tokens**| `RAGConfig.max_context_tokens`   |
| Backups automÃ¡ticos mantidos    | **5**           | `DatabaseGuard._MAX_BACKUPS`     |
| Tamanho bloco hash SHA-256      | 64 KiB          | `IngestionService._compute_file_hash` |

---

## 10. Erros e ExceÃ§Ãµes

### Hierarquia

```
BotSalinhaError
â””â”€â”€ IngestionError
    â””â”€â”€ DuplicateDocumentError
```

### `DuplicateDocumentError`

LanÃ§ada quando um arquivo com o mesmo SHA-256 jÃ¡ estÃ¡ indexado.

```python
class DuplicateDocumentError(IngestionError):
    existing_id:   int   # ID do DocumentORM existente
    existing_nome: str   # Nome do documento existente
    file_hash:     str   # SHA-256 em hex (64 chars)

# Mensagem automÃ¡tica:
# "Arquivo jÃ¡ indexado como 'CF/88' (id=1). Hash: e3b0c4â€¦
#  Para substituir, use !reindexar."
```

**Tratamento recomendado:**

```python
try:
    doc = await ingestion_service.ingest_document(path, nome)
except DuplicateDocumentError as e:
    # Informa o usuÃ¡rio sem re-processar
    await ctx.send(
        f"âš ï¸ **Arquivo jÃ¡ indexado** como `{e.existing_nome}` (id={e.existing_id}).\n"
        f"Use `!reindexar` para reconstruir o Ã­ndice completo."
    )
```

### Outras exceÃ§Ãµes relevantes

| ExceÃ§Ã£o            | Quando                                               |
| ------------------ | ---------------------------------------------------- |
| `IngestionError`   | Falha em qualquer etapa do pipeline (parse, embedâ€¦)  |
| `APIError`         | Falha na API da OpenAI (embedding ou timeout)        |
| `ValidationError`  | Embedding com dimensÃ£o â‰  1536 (detectado no ChunkORM)|

---

## ReferÃªncias Cruzadas

| Componente              | Arquivo                                        |
| ----------------------- | ---------------------------------------------- |
| ORM `DocumentORM`       | `src/models/rag_models.py`                     |
| ORM `ChunkORM`          | `src/models/rag_models.py`                     |
| Pydantic `RAGContext`   | `src/rag/models.py`                            |
| Pydantic `ChunkMetadata`| `src/rag/models.py`                            |
| `IngestionService`      | `src/rag/services/ingestion_service.py`        |
| `QueryService`          | `src/rag/services/query_service.py`            |
| `EmbeddingService`      | `src/rag/services/embedding_service.py`        |
| `VectorStore`           | `src/rag/storage/vector_store.py`              |
| `ConfiancaCalculator`   | `src/rag/utils/confianca_calculator.py`        |
| `MetadataExtractor`     | `src/rag/utils/metadata_extractor.py`          |
| `ChunkExtractor`        | `src/rag/parser/chunker.py`                    |
| `DOCXParser`            | `src/rag/parser/docx_parser.py`                |
| `RAGConfig`             | `src/config/settings.py`                       |
| `DatabaseGuard`         | `src/storage/db_guard.py`                      |
| MigraÃ§Ãµes RAG           | `migrations/versions/20260228_*`               |
