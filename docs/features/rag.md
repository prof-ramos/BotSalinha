# Feature RAG (Retrieval-Augmented Generation)

## Vis√£o Geral

O BotSalinha implementa um sistema RAG que permite respostas jur√≠dicas fundamentadas em documentos reais (Constitui√ß√£o Federal de 1988 e Lei 8.112/90), com cita√ß√µes precisas e indicadores de confian√ßa.

## Arquitetura

```
DOCX/PDF ‚Üí Parser ‚Üí MetadataExtractor ‚Üí ChunkExtractor ‚Üí EmbeddingService ‚Üí SQLite/Qdrant
                                                                   ‚Üì
Usuario ‚Üí Discord ‚Üí QueryService ‚Üí VectorStore (SQLite ou Qdrant) ‚Üí Agno ‚Üí Resposta com Fontes
```

## Componentes

### 1. Modelos de Dados

#### DocumentORM
- Representa um documento indexado (CF/88, Lei 8.112/90)
- Campos: `nome`, `arquivo_origem`, `chunk_count`, `token_count`

#### ChunkORM
- Representa um fragmento de texto com embedding
- Campos: `id`, `documento_id`, `texto`, `metadados` (JSON), `embedding` (BLOB)

### 2. Servi√ßos RAG

#### IngestionService (`src/rag/services/ingestion_service.py`)
Respons√°vel por ingerir documentos DOCX no sistema RAG.

**Pipeline:**
1. Parse DOCX com `DOCXParser`
2. Extrair metadados com `MetadataExtractor`
3. Criar chunks com `ChunkExtractor`
4. Gerar embeddings com `EmbeddingService`
5. Salvar no banco SQLite

**M√©todo principal:**
```python
await ingestion_service.ingest_document(
    file_path="docs/plans/RAG/cf_de_1988_atualiz_ate_ec_138.docx",
    document_name="CF/88"
)
```

#### QueryService (`src/rag/services/query_service.py`)
Orquestra a busca sem√¢ntica e retorna contexto RAG.

**M√©todo principal:**
```python
rag_context = await query_service.query(
    query_text="Quais s√£o os direitos fundamentais?",
    top_k=5,
    min_similarity=0.6
)
```

**Retorna:**
- `chunks_usados`: Lista de chunks relevantes
- `similaridades`: Scores de similaridade (0-1)
- `confianca`: N√≠vel de confian√ßa (ALTA/M√âDIA/BAIXA/SEM_RAG)
- `fontes`: Lista de cita√ß√µes formatadas

#### VectorStore (`src/rag/storage/vector_store.py`)
Implementa busca vetorial com similaridade de cosseno em SQLite.

**Caracter√≠sticas:**
- Armazena embeddings como BLOB (float32 arrays)
- Busca por similaridade de cosseno com numpy
- Suporte a filtros por documento e metadados

#### ConfiancaCalculator (`src/rag/utils/confianca_calculator.py`)
Calcula n√≠vel de confian√ßa baseado na similaridade m√©dia.

**N√≠veis:**
- **ALTA** (‚â•0.85): Resposta baseada em documentos
- **M√âDIA** (0.70-0.84): Parcialmente baseada
- **BAIXA** (0.60-0.69): Informa√ß√µes limitadas
- **SEM_RAG** (<0.60): Conhecimento geral

## Comandos Discord

### `!fontes`
Lista documentos jur√≠dicos indexados no RAG.

**Uso:**
```
!fontes
```

**Resposta:**
```
üìö Fontes RAG Indexadas

CF/88
2450 chunks | 125000 tokens

Lei 8.112/90
850 chunks | 42000 tokens

Total: 2 documentos
```

### `!reindexar` (Admin apenas)
Recria o √≠ndice RAG do zero. Deleta todos chunks e documentos, ent√£o reingesta todos os arquivos DOCX.

**Uso:**
```
!reindexar
```

**Requisitos:**
- Apenas o dono do bot pode executar
- Documentos DOCX devem estar em `data/documents/`

**Resposta:**
```
‚úÖ Reindexa√ß√£o RAG Conclu√≠da!

üìÑ Documentos processados: 2
üì¶ Chunks criados: 3300
‚è±Ô∏è Tempo total: 12.5s

O √≠ndice RAG foi reconstru√≠do com sucesso.
```

## Configura√ß√µes

### Vari√°veis de Ambiente

```bash
# .env (formato aninhado com __ √© obrigat√≥rio para RAG)
RAG__ENABLED=true                    # Habilitar/desabilitar RAG
RAG__TOP_K=5                         # N√∫mero de chunks a recuperar
RAG__MIN_SIMILARITY=0.6              # Similaridade m√≠nima aceit√°vel
RAG__MAX_CONTEXT_TOKENS=2000         # M√°ximo de tokens no contexto
RAG__CONFIDENCE_THRESHOLD=0.70       # Limiar para confian√ßa m√©dia
RAG__VECTOR_BACKEND=sqlite            # sqlite (padrao) ou qdrant
RAG__QDRANT_URL=http://localhost:6333 # URL do Qdrant
RAG__QDRANT_COLLECTION=botsalinha_chunks
OPENAI_API_KEY=sk-...                # Usada para embeddings
```

### Configura√ß√£o YAML (`config.yaml`)

```yaml
rag:
  enabled: true
  top_k: 5
  min_similarity: 0.6
  confidence_threshold: 0.70
```

## Estrat√©gia de Chunking

### Configura√ß√£o

```python
CHUNK_CONFIG = {
    "max_tokens": 500,           # Tamanho m√°ximo por chunk (~2000 chars)
    "overlap_tokens": 50,        # Overlap entre chunks (~200 chars)
    "respect_boundaries": True,  # N√£o quebrar artigos/incisos
    "min_chunk_size": 100,       # Tamanho m√≠nimo v√°lido
}
```

### Metadados Extra√≠dos

| Campo | Fonte | Exemplo |
|-------|-------|---------|
| `documento` | Nome do arquivo | "CF/88" |
| `titulo` | Estilo "Heading 1-9" | "T√çTULO II" |
| `capitulo` | Estilo "Heading 1-9" | "CAP√çTULO I" |
| `artigo` | Regex "Art\.?\s+\d+" | "Art. 5o" |
| `paragrafo` | Regex "[¬ß\d]+" | "¬ß 1o" |
| `inciso` | Regex "[IVX]+" | "Inciso I" |
| `tipo` | Estrutura do chunk | "caput", "inciso" |
| `banca` | Regex "CEBRASPE\|FCC" | "CEBRASPE" |
| `ano` | Regex "\d{4}" | "2023" |

## Como Indexar Novos Documentos

### 1. Preparar o Documento

- Formato: DOCX (Microsoft Word)
- Estrutura: Usar estilos deHeading (Heading 1-9) para t√≠tulos
- Metadados: Incluir marcadores como `#Aten√ß√£o:`, `#STF:`, `#Concurso:`

### 2. Adicionar ao Diret√≥rio

Coloque o arquivo DOCX em:
```
data/documents/novo_documento.docx
```

### 3. Indexar via CLI ou Discord

```bash
# Via CLI
uv run botsalinha ingest data/documents/novo_documento.docx --name "Nome do Documento"

# Via Discord (admin) ‚Äî reindexar tudo
!reindexar
```

### 4. Verificar

```
!fontes
```

## Estrutura de C√≥digo

```
src/rag/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ models.py                    # Pydantic schemas (Document, Chunk)
‚îú‚îÄ‚îÄ parser/
‚îÇ   ‚îú‚îÄ‚îÄ docx_parser.py          # Parser de DOCX
‚îÇ   ‚îú‚îÄ‚îÄ chunker.py              # Extrator de chunks
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ embedding_service.py    # OpenAI text-embedding-3-small
‚îÇ   ‚îú‚îÄ‚îÄ ingestion_service.py    # Pipeline de ingest√£o
‚îÇ   ‚îî‚îÄ‚îÄ query_service.py        # Busca sem√¢ntica
‚îú‚îÄ‚îÄ storage/
‚îÇ   ‚îî‚îÄ‚îÄ vector_store.py         # SQLite + busca vetorial
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ metadata_extractor.py   # Extra√ß√£o de metadados
```

## Integra√ß√£o com AgentWrapper

O `AgentWrapper` integra RAG automaticamente quando habilitado:

```python
# src/core/agent.py
response, rag_context = await self.agent.generate_response_with_rag(
    prompt=message.content,
    conversation_id=conversation.id,
    user_id=str(user_id),
    guild_id=str(guild_id),
)

# rag_context cont√©m:
# - chunks_usados: Lista de chunks
# - similaridades: Scores de similaridade
# - confianca: N√≠vel de confian√ßa
# - fontes: Lista de cita√ß√µes
```

## Formato de Resposta

### Alta Confian√ßa

```
‚úÖ [ALTA CONFIAN√áA]

Conforme a Constitui√ß√£o Federal de 1988, todos s√£o iguais
perante a lei, sem distin√ß√£o de qualquer natureza...

üìé CF/88, Art. 5, caput
```

### Baixa Confian√ßa

```
‚ùå [BAIXA CONFIAN√áA]

Encontrei informa√ß√µes limitadas sobre este tema na base de documentos.
A resposta abaixo pode n√£o ser completa ou precisa.

[Resposta parcial...]
```

### SEM RAG

```
‚ÑπÔ∏è [SEM RAG]

N√£o encontrei informa√ß√µes espec√≠ficas sobre este tema na base de
documentos (Constitui√ß√£o Federal e Lei 8.112/90).

Posso oferecer uma resposta baseada em conhecimento geral, mas recomendo
verificar em fontes oficiais atualizadas.

[Resposta gen√©rica...]
```

## Logs Estruturados

Eventos de log RAG dispon√≠veis em `src/utils/log_events.py`:

```python
LogEvents.RAG_INGESTAO_INICIADA       # In√≠cio da ingest√£o
LogEvents.RAG_INGESTAO_CONCLUIDA       # Fim da ingest√£o
LogEvents.RAG_BUSCA_INICIADA           # In√≠cio da busca
LogEvents.RAG_BUSCA_CONCLUIDA          # Fim da busca
LogEvents.RAG_CHUNKS_RETORNADOS        # Chunks encontrados
LogEvents.RAG_CONFIDENCE_CALCULADA     # Confian√ßa calculada
LogEvents.RAG_REINDEXACAO_INICIADA     # In√≠cio da reindexa√ß√£o
LogEvents.RAG_REINDEXACAO_CONCLUIDA    # Fim da reindexa√ß√£o
```

## Testes

### Rodar Testes RAG

```bash
# Todos os testes RAG
uv run pytest tests/ -k "rag" -v

# Apenas unit√°rios
uv run pytest tests/unit/rag/ -v

# Apenas E2E
uv run pytest tests/e2e/test_rag_*.py -v

# Com coverage
uv run pytest tests/ -k "rag" --cov=src/rag --cov-report=html
```

### Testes de Recall

```bash
# Testa Recall@5 com 20 perguntas jur√≠dicas
uv run pytest tests/integration/rag/test_recall.py -v
```

## Troubleshooting

### RAG N√£o Retorna Resultados

**Problema:** Consultas retornam SEM_RAG ou BAIXA confian√ßa

**Solu√ß√µes:**
1. Verificar se documentos est√£o indexados: `!fontes`
2. Reindexar: `!reindexar`
3. Verificar `RAG_MIN_SIMILARITY` (muito alto?)
4. Verificar se OPENAI_API_KEY est√° configurada

### Erro de Ingest√£o

**Problema:** Documentos n√£o s√£o indexados

**Solu√ß√µes:**
1. Verificar formato do documento (deve ser DOCX)
2. Verificar estrutura (usar Heading styles)
3. Verificar logs: `tail logs/botsalinha.log | grep rag_ingestion`
4. Testar parser isoladamente

### Lat√™ncia Alta

**Problema:** Respostas demoram > 2 segundos

**Solu√ß√µes:**
1. Reduzir `RAG_TOP_K` (padr√£o: 5)
2. Verificar lat√™ncia da API OpenAI
3. Considerar cache de embeddings

## Custos

### Embeddings

| Opera√ß√£o | Tokens | Custo USD |
|----------|--------|-----------|
| CF/88 (ingest√£o) | ~150K | $0.003 |
| Lei 8.112 (ingest√£o) | ~30K | $0.0006 |
| Query (pergunta) | ~50 | $0.00001 |
| **Total (one-time)** | ~180K | **$0.004** |

### Operacional

| Opera√ß√£o | Por Query | 1000 queries | 10K queries |
|----------|-----------|--------------|-------------|
| RAG (embedding + LLM) | ~$0.001 | ~$0.15 | ~$1.50 |

## Refer√™ncias

- [Schema T√©cnico Completo do RAG](../rag_schema.md)
- [Modelos ORM RAG](../../src/models/rag_models.py)
- [Configura√ß√µes RAG](../../src/config/settings.py)
- [Decis√µes Arquiteturais](../plans/RAG/decisoes_arquiteturais.md)
