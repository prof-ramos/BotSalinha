# Melhorias Sugeridas - RAG Jur√≠dico BotSalinha

**Data:** 2026-02-28
**Fonte:** An√°lise de implementa√ß√£o de refer√™ncia

## Vis√£o Geral

Este documento registra melhorias e descobertas obtidas a partir da an√°lise de uma implementa√ß√£o de refer√™ncia de RAG jur√≠dico para Discord, comparando com a implementa√ß√£o atual do BotSalinha.

## Decis√µes Arquiteturais: BotSalinha vs Refer√™ncia

| Aspecto | BotSalinha (Atual) | Refer√™ncia Externa | Justificativa |
|---------|-------------------|-------------------|---------------|
| **Vector Store** | SQLite + √≠ndice vetorial customizado | ChromaDB | Menos depend√™ncias, controle total, SQLite j√° em uso |
| **Embeddings** | OpenAI text-embedding-3-small (API) | sentence-transformers (local) | Maior qualidade para portugu√™s jur√≠dico, $0.02/1M tokens |
| **Orquestra√ß√£o** | Agno Framework | LangChain | Agno j√° em uso no projeto |
| **Chunking** | Hier√°rquico (t√≠tulo‚Üícap√≠tulo‚Üíse√ß√£o‚Üíartigo) | Por tamanho fixo | Preserva estrutura jur√≠dica |
| **Formata√ß√£o** | Markdown simples | Prefixos visuais (emojis) | ‚úÖ Melhoria sugerida abaixo |

---

## Melhorias Sugeridas

### 1. Normaliza√ß√£o de Encoding ‚ö†Ô∏è **Alta Prioridade**

**Problema:** Documentos jur√≠dicos brasileiros frequentemente usam encoding latin-1, causando caracteres corrompidos.

**Solu√ß√£o da Refer√™ncia:**
```python
# normalizador.py
def normalize_encoding(text: str) -> str:
    """
    Normaliza encoding de documentos jur√≠dicos brasileiros.
    Converte latin-1 ‚Üí utf-8 e remove caracteres problem√°ticos.
    """
    # Substitui√ß√µes comuns de encoding latin-1 corrompido
    replacements = {
        "√É¬ß": "√ß", "√É¬£": "√£", "√É¬µ": "√µ", "√É¬°": "√°", "√É¬©": "√©",
        "√É¬≠": "√≠", "√É¬≥": "√≥", "√É¬∫": "√∫", "√É¬¢": "√¢", "√É¬™": "√™",
        "√É¬¥": "√¥", "√É¬≠": "√≠", "√É ": "√†", "√É¬Å": "√Å", "√É‚Ä∞": "√â",
        "√¢‚Ç¨≈ì": '"', "√¢‚Ç¨¬ù": '"', "√¢‚Ç¨Àú": "'", "√¢‚Ç¨‚Ñ¢": "'",
    }

    for wrong, correct in replacements.items():
        text = text.replace(wrong, correct)

    return text
```

**Implementa√ß√£o Sugerida:**
- Adicionar `src/rag/utils/normalizer.py`
- Integrar no `DOCXParser.parse()` ap√≥s leitura de cada par√°grafo
- Adicionar testes para caracteres problem√°ticos comuns

---

### 2. Prefixos Visuais para Tipos de Chunk üìã

**Problema:** Chunks de diferentes tipos jur√≠dicos ficam dif√≠ceis de distinguir visualmente.

**Solu√ß√£o da Refer√™ncia:**
```python
CHUNK_PREFIXES = {
    "artigo": "‚öñÔ∏è",
    "jurisprudencia": "üìú",
    "questao": "‚ùì",
    "nota": "üìù",
    "lei": "üìã",
}

def format_chunk(chunk: Chunk) -> str:
    prefix = CHUNK_PREFIXES.get(chunk.tipo, "üìÑ")
    return f"{prefix} {chunk.texto}"
```

**Implementa√ß√£o Sugerida:**
- Adicionar campo `tipo: str` em `ChunkMetadata`
- Implementar `formatador.py` com prefixos
- Usar na resposta do Discord para melhor UX

---

### 3. Filtragem por Tipo de Metadado üîç

**Problema:** Usu√°rios podem querer buscar apenas artigos, ou apenas jurisprud√™ncia.

**Solu√ß√£o da Refer√™ncia:**
```python
# Slash command /buscar
@bot.command("/buscar")
async def buscar(
    ctx,
    query: str,
    tipo: Literal["artigo", "jurisprudencia", "questao", "nota", "todos"] = "todos"
):
    results = vector_store.search(query, tipo_filter=tipo)
```

**Implementa√ß√£o Sugerida:**
- Adicionar par√¢metro `tipo` em `QueryService.query()`
- Mapear `ChunkMetadata` para tipos:
  - `artigo`: tem campo `artigo` preenchido
  - `jurisprudencia`: marcas `marca_stf` ou `marca_stj`
  - `questao`: tem campo `banca` preenchido
  - `nota`: texto curto (< 100 tokens)
- Comando Discord: `!buscar <query> [--tipo artigo|jurisprudencia|questao|nota]`

---

### 4. Comandos Discord Adicionais üí¨

**Comando `/fontes`**
```python
@commands.command(name="fontes")
async def fontes(self, ctx):
    """Lista documentos indexados no RAG."""
    docs = await repository.list_documents()
    response = "**Fontes Jur√≠dicas Indexadas:**\n\n"
    for doc in docs:
        response += f"üìã {doc.nome} ({doc.chunk_count} chunks)\n"
    await ctx.send(response)
```

**Comando `/limpar`** (j√° existe `!limpar` para conversas)
```python
@commands.command(name="reindexar")
async def reindexar(self, ctx, document_name: str):
    """Reindexa um documento do zero."""
    # Limpa chunks existentes
    # Reingesta documento
    await ctx.send(f"‚úÖ Documento {document_name} reindexado.")
```

---

### 5. Categoriza√ß√£o de Confian√ßa üéØ

**Problema:** Usu√°rios precisam saber o qu√£o confiante √© o RAG para a resposta.

**Solu√ß√£o da Refer√™ncia:**
```python
def get_confidence_category(similarity: float) -> str:
    """Retorna categoria de confian√ßa baseada em similaridade."""
    if similarity >= 0.85:
        return "ALTA"  # ‚úÖ
    elif similarity >= 0.70:
        return "MEDIA"  # ‚ö†Ô∏è
    else:
        return "BAIXA"  # ‚ùå
```

**Implementa√ß√£o Sugerida:**
- J√° implementado em `ConfiancaLevel` enum (`ALTA`, `MEDIA`, `BAIXA`, `SEM_RAG`)
- Adicionar indicadores visuais na resposta Discord:
  - `ALTA` ‚Üí ‚úÖ Fontes confi√°veis
  - `MEDIA` ‚Üí ‚ö†Ô∏è Verifique as fontes
  - `BAIXA` ‚Üí ‚ùå Baixa confian√ßa nas fontes
  - `SEM_RAG` ‚Üí ‚ÑπÔ∏è Resposta sem base jur√≠dica espec√≠fica

---

## Li√ß√µes Aprendidas

### Do Milestone 0 (Funda√ß√£o)

‚úÖ **Bem-sucedido:**
- Pydantic v2 com `env_nested_delimiter="__"` funciona bem
- SQLAlchemy 2.0 async ORM com `Mapped[]` annotations
- Migra√ß√£o Alembic manual quando `--autogenerate` falha

‚ö†Ô∏è **Problemas Resolvidos:**
1. **Nested classes Pydantic-settings** n√£o herdam `env_file` automaticamente
   - Solu√ß√£o: Adicionar `env_file=".env"` explicitamente em cada classe aninhada

2. **API key n√£o lida do .env** em nested configs
   - Solu√ß√£o: Workaround no CLI lendo `os.environ` diretamente

### Do Milestone 1 (Ingest√£o)

‚úÖ **Bem-sucedido:**
- `python-docx` preserva estrutura hier√°rquica bem
- Regex para extra√ß√£o de metadados jur√≠dicos funciona
- Dynamic batching resolve limite de 300K tokens da OpenAI

‚ö†Ô∏è **Problemas Resolvidos:**
1. **Limite de tokens OpenAI excedido**
   - Documento CF/88 com 312K tokens falhou
   - Solu√ß√£o: Implementar batching din√¢mico em `EmbeddingService.embed_batch()`

2. **Estimativa de tokens imprecisa**
   - Solu√ß√£o: Usar `len(text) // 4` como aproxima√ß√£o para portugu√™s

---

## Status das Melhorias

| Melhoria | Status |
|----------|--------|
| Normaliza√ß√£o de encoding (`normalize_encoding`) | ‚úÖ Implementado em `src/rag/utils/normalizer.py` |
| Prefixos visuais por tipo de chunk | ‚úÖ Implementado em `QueryService.get_augmentation_text()` |
| Filtragem por tipo de metadado | ‚úÖ Implementado em `QueryService.query_by_tipo()` |
| Indicadores visuais de confian√ßa | ‚úÖ Implementado em `ConfiancaCalculator.get_confidence_message()` |
| Comando `!reindexar` | ‚úÖ Implementado |
| Comando `!fontes` | ‚úÖ Implementado |
| Comando `!buscar <tipo>` | ‚úÖ Implementado |

## Pr√≥ximas Melhorias (Post-MVP)

- [ ] Suporte a PDF nativo
- [ ] Re-ranking por relev√¢ncia jur√≠dica
- [ ] Hybrid search (sem√¢ntico + BM25)

---

## Refer√™ncias

- **Implementa√ß√£o Atual:** `src/rag/`
- **Schema T√©cnico:** [`docs/rag_schema.md`](../../rag_schema.md)
